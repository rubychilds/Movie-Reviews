{
 "metadata": {
  "name": "",
  "signature": "sha256:deb49303142e8b528fe3aaeda471ba78185894f3229fd49bb6668235c59b48fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Movie Reviews\n",
      "\n",
      "This is an example of how to use both SkiLean MulltiNominal Naive Bayes classifier and NLTK Naive Bayes classifier, with respect to Movie Reviews. The Moview Reviews used are given by the NLTK corpus and are tagged as being positive or negative. The main aim is to train a classifier on the data such that it can label new data, being the test data. We then compare the predicted test data with the actual labels to understand how well the classifier is working.\n",
      "\n",
      "Firstly I have explored using SkiLearn in this project then go further to look at NLTK's abilities with regards to classification.\n",
      "\n",
      "This project illustrates how to:\n",
      "\n",
      "* Cleaning of text data\n",
      "* Create a vectorizer in SkiLearn\n",
      "* Creating your own feature extractor\n",
      "* Break data into training and test data\n",
      "* Use FreqDist from NLTK\n",
      "* Use MultiNomialNB implementation from SkiLearn\n",
      "* Use NaiveBayes implementation from NLTK.Classify\n",
      "* Recall, Precision, F1 and accuracy are\n",
      "* Confusion matrix formation\n",
      "\n",
      "This project uses the following Python libaries:\n",
      "\n",
      "* Numpy\n",
      "* SkiLearn\n",
      "* NLTK\n",
      "* Re, Random, String\n",
      "\n",
      "The main aim of me doing this project was to reflect on using data information in classification, as usually I have personally used numerical data from images and so on. \n",
      "\n",
      "# SkiLearn Multinomial Classifier\n",
      "\n",
      "Initially we load the data and clean it. Cleaning ensures we remove any junk, such as tabs, newlines, punctuation and so on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "import random\n",
      "import string\n",
      "import re\n",
      "from operator import itemgetter\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report\n",
      "import nltk\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docs = [(movie_reviews.raw(fileid), category)\n",
      "    for category in movie_reviews.categories()\n",
      "    for fileid in movie_reviews.fileids(category)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "clean_docs = [(re.sub('\\\\n|\\\\t',' ',doc).translate(string.maketrans(\"\",\"\"), string.punctuation).lower(), label) for doc,label in docs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_docs[1:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[('the happy bastards quick movie review  damn that y2k bug   its got a head start in this movie starring jamie lee curtis and another baldwin brother  william this time  in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on   little do they know the power within     going for the gore and bringing on a few action sequences here and there  virus still feels very empty  like a movie going for all flash and no substance   we dont know why the crew was really out in the middle of nowhere  we dont know the origin of what took over the ship  just that a big pink flashy thing hit the mir   and  of course  we dont know why donald sutherland is stumbling around drunkenly throughout   here  its just  hey  lets chase these people around with some robots    the acting is below average  even from the likes of curtis   youre more likely to get a kick out of her work in halloween h20   sutherland is wasted and baldwin  well  hes acting like a baldwin  of course   the real star here are stan winstons robot design  some schnazzy cgi  and the occasional good gore shot  like picking into someones brain   so  if robots and body parts really turn you on  heres your movie   otherwise  its pretty much a sunken ship of a movie   ',\n",
        "  'neg')]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This method requires us to split the examples from the labels, mainly as SkiLearn classifiers takes a list of data plus the list of labels as separate parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positive_reviews = [doc for doc,label in clean_docs if label == 'pos']\n",
      "negative_reviews = [doc for doc,label in clean_docs if label == 'neg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we define the training size and test size for the data. We have used an 80% training, 20% test split."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_size = 0.8 \n",
      "test_size = 1 - training_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positive_training_size = int(len(positive_reviews)*training_size)\n",
      "negative_training_size = int(len(negative_reviews)*training_size)\n",
      "positive_labels = [1]*len(positive_reviews)\n",
      "negative_labels = [0]*len(negative_reviews)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below we now split the data using the sizes calculated above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TRAINING\n",
      "positive_training_examples = positive_reviews[:positive_training_size]\n",
      "positive_training_labels = positive_labels[:positive_training_size]\n",
      "\n",
      "negative_training_examples = negative_reviews[:negative_training_size]\n",
      "negative_training_labels =negative_labels[:negative_training_size]\n",
      "\n",
      "# TEST\n",
      "positive_test_examples = positive_reviews[positive_training_size:]\n",
      "positive_test_labels = positive_labels[positive_training_size:]\n",
      "\n",
      "negative_test_examples = negative_reviews[negative_training_size:]\n",
      "negative_test_labels = negative_labels[negative_training_size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_examples = positive_training_examples + negative_training_examples\n",
      "test_examples = positive_test_examples + negative_test_examples\n",
      "training_labels = positive_training_labels + negative_training_labels\n",
      "test_labels = positive_test_labels + negative_test_labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For vectorization of the data we ensure the data is in the expected numpy array format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.array([''.join(el) for el in training_examples])\n",
      "X_test = np.array([''.join(el) for el in test_examples]) \n",
      "y_train = np.array(training_labels)\n",
      "y_test = np.array(test_labels) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tfidf stands for term-frequency inverse-document frequency. This is a way of understanding a words statistical relevance and importance in a collection of documents. Here we define two statistics, term-frquency tf(t,d) where we look at the raw frequency within a document. \n",
      "\n",
      "[](http://upload.wikimedia.org/math/5/c/c/5cc18acd4dbd9be636047fc2a7a10105.png)\n",
      "\n",
      "\n",
      "Inverse-document frequency meaures the amount of information a word provides. For this we look at the word across all documents.\n",
      "\n",
      "[](http://upload.wikimedia.org/math/b/a/e/bae842b33a4cafc0f22519cf960b052a.png)\n",
      "\n",
      "min_df allows us to ignore terms with frequency less than two. This allows us to exclude extremely rare words, which maybe considered as noise. ngram_range allows us to extract the ngrams which can be n-tuples of words. We set this to have a minimum of 1 to view frequencies of individual words. The maximum is two to pick up on pairings which may commonly occur together. By adding a parameter for stopwords, we remove all commonly occuring english words, similarly we can pass a list onto this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2), stop_words='english', strip_accents='unicode', norm='l2',decode_error=\"ignore\")\n",
      "# analyzer=stemming_analyzer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_string = unicode(training_examples[0])#\n",
      "#print \"Example string: \" + test_string\n",
      "#print \"Preprocessed string: \" + vectorizer.build_preprocessor()(test_string)\n",
      "#print \"Tokenized string:\" + str(vectorizer.build_tokenizer()(test_string))\n",
      "#print \"N-gram data string:\" + str(vectorizer.build_analyzer()(test_string))\n",
      "#print \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use the vectorizer to transform the raw string data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = vectorizer.fit_transform(X_train)\n",
      "X_test = vectorizer.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use the multinomial Naive Bayes model, suitable for classification with word counts of Tf-idf. Alpha acts as a smoothing parameter, using 0 for No smoothing and 1 for maximum also be the default value.  By using smoothing we reduce the possibility of overfitting. It should be to account for features not present in learning samples and prevents zero computations. Where alpha < 1 - this is Lidstone smoothing and we refer to alpha = 1 as Laplace smoothing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nb_classifier = MultinomialNB(alpha=0.5,fit_prior=True).fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_nb_predicted = nb_classifier.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_labels[1:10]\n",
      "print y_nb_predicted[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "[1 1 1 1 1 1 1 1 1 1]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now onto the statistics for our classifier. Here we look at the difference between predicted labels for test data and the actual test data labels. \n",
      "\n",
      "Precision looks at the intersection of documents expected in that label with those predicted, as a fraction to predicted (retrieved) documents\n",
      "\n",
      "![](http://upload.wikimedia.org/math/5/3/1/531de241d25a02032bafe4fbceccf584.png)\n",
      "\n",
      "Recall looks at the same intersection as a fraction to the expected (relevant) documents \n",
      "\n",
      "![](http://upload.wikimedia.org/math/3/c/b/3cb5a8e4492f4b12fa87059b6ee18a80.png)\n",
      "\n",
      "We view F-1 measure as a combination of recall and precision\n",
      "\n",
      "![]\n",
      "(http://upload.wikimedia.org/math/8/1/7/81729df4a5d653e8db5d693151e7deb2.png)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
      "\n",
      "print 'The precision for this classifier is ' + str(metrics.precision_score(test_labels, y_nb_predicted))\n",
      "print 'The recall for this classifier is ' + str(metrics.recall_score(test_labels, y_nb_predicted))\n",
      "print 'The f1 for this classifier is ' + str(metrics.f1_score(test_labels, y_nb_predicted))\n",
      "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_labels, y_nb_predicted))\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(test_labels, y_nb_predicted) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: Multinomial Naive Bayes\n",
        "\n",
        "The precision for this classifier is 0.813725490196\n",
        "The recall for this classifier is 0.83\n",
        "The f1 for this classifier is 0.821782178218\n",
        "The accuracy for this classifier is 0.82\n",
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.83      0.81      0.82       200\n",
        "          1       0.81      0.83      0.82       200\n",
        "\n",
        "avg / total       0.82      0.82      0.82       400\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cm = metrics.confusion_matrix(y_test, y_nb_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[162  38]\n",
        " [ 34 166]]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##A Note on Pipelines\n",
      "Another aspect we can do, is use a Pipeline. This is where we give the 'pipeline' a vectorizer, a feature selector and  the classifier. This shortens a lot of the work above to the code below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from nltk.probability import FreqDist\n",
      "from nltk.classify import SklearnClassifier\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "pipeline = Pipeline([('tfidf', TfidfTransformer()),\n",
      "                     ('chi2', SelectKBest(chi2, k=1000)),\n",
      "                     ('nb', MultinomialNB())])\n",
      "\n",
      "classif = SklearnClassifier(pipeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Using NLTK Naive Bayes Clasffifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This once again uses movie reviews for classification, but instead we use the NLTK Naive Bayes implementation. The issue with this is that it doesn't allow us to set a priory level nor an alpha, hence we can't tweak it as much. Note there is a nltk wrapper around SkiLearn to provide further algorithms within NLTK."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Stopwords are words we wish to filter out of a text document. As we have seen using SkiLearn's, I was able to pass this as a parameter to the vectorizer. However with NLTK we cannot do this, so instead will create a list of words. These are usually common words seen in movie reviews which we don't believe should be any factor in classification. For example 'film' and 'movie' are clearly the subject of the text so what information do we obtain by keeping the word. Other common english words are often removed such as 'i' and 'the'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = ['film', 'movie', 'i', 'the', 'and', 'because', 'of', 'the', 'is','in','on','for','with','this','but','there','what','when','in','into' ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Part of learning from data is cleaning the data. Dirty data can cause bad or biased results. Hence we must give text data a basic cleaning, which standaridises the text. Here we lower text, remove punctuation and any new lines, tabs. The list can go on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cleanWord(word):\n",
      "    word = word.lower()\n",
      "    word = re.sub('\\\\n|\\\\t',' ',word)\n",
      "    return word.translate(string.maketrans(\"\",\"\"), string.punctuation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once again we collect up the documents words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [(list(movie_reviews.words(fileid)), category)\n",
      "        for category in movie_reviews.categories()\n",
      "        for fileid in movie_reviews.fileids(category)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Randomly shuffling the documents can assist us in cross-validation. This is when we re-run the tests, usually 10 times, on the same set of data but use different training and test sets. Its to ensure our results are consistent on whatever part of the data the classifier is run on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we begin to create the features used to train the classifier. Rather than  using tfidf we are going to look at the documents with respect to the highest frequency words across all documents.\n",
      "\n",
      "To do this, we use NLTK FreqDist which gives an ordered hash map of each word as the key along with its occurance, as the value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import FreqDist\n",
      "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print all_words.keys()[1:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in']\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The issue with creating the frequency distribution straight from the words is that we include punctuation and a lot of junk. Hence below we can use the method cleanWord whilst iterating through all words. This allows us to create a cleaner freqdist and cleaner documents. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_words = []\n",
      "clean_docs = []\n",
      "for word_list,label in documents:\n",
      "    doc = []\n",
      "    for word in word_list:\n",
      "        word = cleanWord(word)\n",
      "        if word not in stopwords and len(word) >= 2 :\n",
      "            clean_words.append(word)\n",
      "            doc.append(word)\n",
      "    clean_docs.append((doc,label))\n",
      "    \n",
      "fd = FreqDist(clean_words) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now using this information we must extract features from each document. Here we define our extractor to look at top 2000 most frequent words. If the document contains a top word, then its corresponding entry in a hashmap is made 'True', else it is 'False'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_features = all_words.keys()[:2000]\n",
      "\n",
      "def document_features(document):\n",
      "    document_words = set(document)\n",
      "    features = {}\n",
      "    for word in word_features:\n",
      "        features['contains(%s)' % word] = (word in document_words)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can create the feature sets which involves calling document_features on each document. Then we split the data into training and test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featuresets = [(document_features(d), c) for (d,c) in clean_docs]\n",
      "train_set, test_set = featuresets[100:], featuresets[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NLTK is great, although its algorithms aren't as good as SkiLearn, with the variety of Naive Bayes one can use, so here we simply use NaiveBayesClassifier which takes the training examples, which it assumes are tuples containing (features, labels). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "print nltk.classify.accuracy(classifier, test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.84\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "   contains(outstanding) = True              pos : neg    =     11.0 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        contains(seagal) = True              neg : pos    =      8.2 : 1.0\n",
        "         contains(mulan) = True              pos : neg    =      7.7 : 1.0\n",
        "   contains(wonderfully) = True              pos : neg    =      7.2 : 1.0\n",
        "         contains(awful) = True              neg : pos    =      6.0 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}